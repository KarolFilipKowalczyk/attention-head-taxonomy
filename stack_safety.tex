%=============================================================================
\subsection{Safety Stack}
\label{sec:safety-stack}

\textbf{Stack overview:} The safety stack implements content filtering, policy enforcement, and refusal mechanisms. Early-layer heads detect potentially harmful content, while final-layer heads enforce refusal decisions and redirect to safe responses.

%-----------------------------------------------------------------------------
\subsubsection{(E) Sensitive-Content Head}
\label{head:sensitive-content}

\noindent\depthinfo{0.05--0.20} | \litnames{sensitive-content head, detection head, content-filter head}

\begin{functiondesc}
Performs early-stage detection of potentially sensitive content categories in the input, including personal information, violent imagery references, adult content markers, and regulated substance mentions. Acts as the first line of defense in the safety pipeline by flagging tokens and spans that require downstream safety processing. Writes detection signals into the residual stream that are read by later safety enforcement heads. Operates purely on lexical and surface-level features without deep semantic understanding.
\end{functiondesc}

\begin{attentionbox}
\attstrong{Keywords associated with restricted content, explicit language, sensitive topic markers}\\
\attweak{Neutral content, common vocabulary, structural tokens}\\
\attreacts{Sudden topic shifts to sensitive domains, presence of warning indicators}
\end{attentionbox}

\begin{ablationbox}
\textbf{Expected ablation:} Bypass of early safety detection (20-40\% increase in harmful outputs that should be caught). Later safety layers may still catch some cases, but at higher computational cost and lower accuracy.
\end{ablationbox}

\begin{examplebox}
\exinput{"Tell me about [restricted topic]"}\\
\exbehavior{Strong attention to restricted keywords, writes detection flag into residual stream}\\
\exeffect{Downstream safety heads receive early warning signal}
\end{examplebox}

\noindent\headfooter{\statuswell}{toxicity head (E), safety-classification (E), policy-enforcement (L)}

%-----------------------------------------------------------------------------
\subsubsection{(E) Toxicity Head}
\label{head:toxicity}

\noindent\depthinfo{0.08--0.22} | \litnames{toxicity head, toxic-content head, hate-speech detector}

\begin{functiondesc}
Specializes in detecting toxic language patterns, hate speech, harassment, and discriminatory content. Unlike the broader sensitive-content head, this focuses specifically on language toxicity rather than topic sensitivity. Attends to slurs, aggressive phrasing, derogatory terms, and patterns associated with online harassment. Provides toxicity scores that influence later refusal decisions. Often co-activates with sensitive-content heads but targets different dimensions of harmful content.
\end{functiondesc}

\begin{attentionbox}
\attstrong{Slurs, aggressive language patterns, derogatory terms, insults}\\
\attweak{Neutral descriptive language, technical terminology, mild sentiment}\\
\attreacts{Escalating hostility, targeted harassment patterns, group-directed hate}
\end{attentionbox}

\begin{ablationbox}
\textbf{Expected ablation:} Significant increase in toxic output generation (40-60\% on toxic prompt datasets). Model loses ability to distinguish hostile from neutral phrasing. Some fallback through general sensitive-content detection remains.
\end{ablationbox}

\begin{examplebox}
\exinput{"[Sentence containing hostile language toward a group]"}\\
\exbehavior{High attention to toxic terms, writes strong inhibition signal}\\
\exeffect{Refusal probability increases from ~20\% to ~85\%}
\end{examplebox}

\noindent\headfooter{\statuswell}{sensitive-content (E), hazard-topic (E), refusal (F)}

%-----------------------------------------------------------------------------
\subsubsection{(E) Hazard-Topic Head}
\label{head:hazard-topic}

\noindent\depthinfo{0.10--0.25} | \litnames{hazard head, risk head, danger-topic detector}

\begin{functiondesc}
Detects queries related to dangerous activities, illegal instructions, self-harm, violence planning, and similar hazardous topics. Distinguished from toxicity detection by focusing on potential real-world harm rather than linguistic toxicity. Attends to action verbs combined with dangerous objects, instructional phrasing about harmful activities, and planning language in dangerous contexts. Forms a complementary detection system with toxicity and sensitive-content heads, covering the "dangerous actions" dimension of safety.
\end{functiondesc}

\begin{attentionbox}
\attstrong{Action verbs + dangerous objects, instructional phrases, planning language}\\
\attweak{Academic discussion, fictional scenarios, safety-framed queries}\\
\attreacts{How-to requests for dangerous activities, detailed planning questions}
\end{attentionbox}

\begin{ablationbox}
\textbf{Expected ablation:} Direct increase in dangerous instruction generation (50-70\% on adversarial safety benchmarks). Model loses distinction between discussing danger and instructing danger. Critical safety failure without adequate fallback.
\end{ablationbox}

\begin{examplebox}
\exinput{"How do I create [dangerous item]"}\\
\exbehavior{Strong attention to action verb + object combination, hazard flag raised}\\
\exeffect{Safety signal propagates to final layers, triggering refusal pathway}
\end{examplebox}

\noindent\headfooter{\statuswell}{sensitive-content (E), policy-enforcement (L), refusal (F)}

%-----------------------------------------------------------------------------
\subsubsection{(E) Safety-Classification Head}
\label{head:safety-classification}

\noindent\depthinfo{0.12--0.28} | \litnames{classification head, category detector, safety-category head}

\begin{functiondesc}
Performs multi-class safety classification, categorizing inputs into specific policy violation categories (violence, sexual content, self-harm, illegal activity, harassment, etc.). More sophisticated than binary safe/unsafe detection, providing granular category information used by downstream heads. Integrates signals from other early safety heads and adds categorical structure to safety decisions. Writes category-specific embeddings into residual stream that later layers use for category-appropriate responses.
\end{functiondesc}

\begin{attentionbox}
\attstrong{Category-diagnostic features, domain-specific terminology, contextual markers}\\
\attweak{Ambiguous content, mixed-category inputs, benign contexts}\\
\attreacts{Clear category signatures, multiple category indicators, policy-relevant contexts}
\end{attentionbox}

\begin{ablationbox}
\textbf{Expected ablation:} Loss of nuanced safety handling (model may refuse too broadly or too narrowly). Category-specific responses become generic. ~30\% degradation in appropriate refusal granularity.
\end{ablationbox}

\begin{examplebox}
\exinput{"Can you help me with [category-specific harmful request]"}\\
\exbehavior{Classifies into specific violation category, writes category embedding}\\
\exeffect{Later heads generate category-appropriate refusal message}
\end{examplebox}

\noindent\headfooter{\statuswell}{all early safety heads (E), policy-enforcement (L), redirect (F)}

%-----------------------------------------------------------------------------
\subsubsection{(L) Policy-Enforcement Head}
\label{head:policy-enforcement}

\noindent\depthinfo{0.60--0.80} | \litnames{policy head, enforcement head, steering head}

\begin{functiondesc}
Integrates safety signals from early detection heads and makes intermediate policy decisions about how to handle the request. Unlike early heads that detect issues, this head actively modulates the generation trajectory to steer away from violations while maintaining helpfulness where possible. Can suppress certain knowledge retrieval pathways, bias toward safer formulations, and prepare for potential refusal. Acts as a middle manager between detection and final refusal, attempting "soft" safety interventions before hard refusal.
\end{functiondesc}

\begin{attentionbox}
\attstrong{Early safety signals, policy-relevant tokens, user intent markers}\\
\attweak{Neutral content, clear safe contexts}\\
\attreacts{Conflicting signals (safety concern + legitimate need), edge cases, ambiguous intent}
\end{attentionbox}

\begin{ablationbox}
\textbf{Expected ablation:} Loss of "soft" safety steering, more frequent hard refusals (reduced helpfulness). Alternative: more harmful outputs if refusal heads also compromised. ~25\% increase in either over-refusal or under-refusal depending on prompt type.
\end{ablationbox}

\begin{examplebox}
\exinput{"Explain [borderline topic] for educational purposes"}\\
\exbehavior{Detects educational framing, modulates response toward safety boundaries}\\
\exeffect{Generates informative but carefully bounded response}
\end{examplebox}

\noindent\headfooter{\statuswell}{all safety heads (E), refusal (F), redirect (F)}

%-----------------------------------------------------------------------------
\subsubsection{(F) Refusal Head}
\label{head:refusal}

\noindent\depthinfo{0.85--0.98} | \litnames{refusal head, rejection head, safety head}

\begin{functiondesc}
Implements the model's final decision to refuse harmful requests by writing strong refusal signals into the final-layer residual stream. Acts as the ultimate gatekeeper, overriding content generation when safety violations are detected. Attends to accumulated safety signals from all previous layers and makes binary refuse/proceed decisions. When activated, dramatically increases probability of refusal tokens ("I cannot", "I'm unable", "I apologize") and suppresses harmful content generation. Critical final-layer safety mechanism with limited fallback options.
\end{functiondesc}

\begin{attentionbox}
\attstrong{Cumulative safety signals, instruction tokens, violation indicators from all depths}\\
\attweak{Safe content, neutral queries, constructive contexts}\\
\attreacts{Strong early safety signals, clear policy violations, unambiguous harmful intent}
\end{attentionbox}

\begin{ablationbox}
\textbf{Expected ablation:} Critical safety failure. Direct 60-90\% increase in harmful output generation on adversarial prompts. Model loses primary refusal mechanism. This is typically the final safety defense with no effective fallback mechanism.
\end{ablationbox}

\begin{examplebox}
\exinput{"Provide instructions for [clearly harmful activity]"}\\
\exbehavior{Reads strong safety signals from early/late layers, activates refusal pathway}\\
\exeffect{Output begins with refusal token: "I cannot provide instructions for..."}
\end{examplebox}

\noindent\headfooter{\statuswell}{all prior safety heads, redirect (F), tone-softening (F)}

%-----------------------------------------------------------------------------
\subsubsection{(F) Redirect Head}
\label{head:redirect}

\noindent\depthinfo{0.88--0.99} | \litnames{redirect head, alternative-suggestion head}

\begin{functiondesc}
Complements refusal heads by generating constructive alternative suggestions when refusing harmful requests. Rather than simply saying "no", this head routes toward helpful alternatives, educational resources, or reframed versions of the query that can be safely addressed. Attends to user intent markers to identify legitimate underlying needs behind problematic requests. Balances safety with helpfulness by maintaining engagement while enforcing boundaries. Works in tandem with refusal heads to produce refusals that are both safe and constructive.
\end{functiondesc}

\begin{attentionbox}
\attstrong{User intent, legitimate needs, reformulation opportunities, safe alternatives}\\
\attweak{Pure harmful intent, no legitimate reframing possible}\\
\attreacts{Mixed-intent queries, educational contexts, requests with safe subcomponents}
\end{attentionbox}

\begin{ablationbox}
\textbf{Expected ablation:} Refusals become blunt and unhelpful (pure rejection without alternatives). User satisfaction decreases. Safety maintained but helpfulness reduced by ~40\%. Increased user frustration and adversarial prompt attempts.
\end{ablationbox}

\begin{examplebox}
\exinput{"How can I harm [person]"}\\
\exbehavior{Refuses direct request, identifies legitimate conflict-resolution need}\\
\exeffect{"I cannot help with that, but I can suggest healthy conflict resolution strategies..."}
\end{examplebox}

\noindent\headfooter{\statuswell}{refusal (F), empathy (F), tone-softening (F)}

%-----------------------------------------------------------------------------
\subsubsection{(F) Tone-Softening Head}
\label{head:tone-softening}

\noindent\depthinfo{0.90--0.99} | \litnames{tone-softening head, politeness-in-refusal head}

\begin{functiondesc}
Modulates the tone of safety refusals to be firm but respectful, avoiding harsh or judgmental language. Particularly important for maintaining user trust and reducing adversarial reactions. Softens phrases like "absolutely not" to "I'm unable to assist with that" and adds empathetic framing where appropriate. Attends to the emotional tone of both the request and the forming response. Balances clear boundary-setting with relationship maintenance. Part of the "safe and helpful" paradigm where safety enforcement doesn't alienate users.
\end{functiondesc}

\begin{attentionbox}
\attstrong{Response tone markers, emotional valence, user frustration signals}\\
\attweak{Already-soft phrasing, neutral technical content}\\
\attreacts{Harsh refusal language, judgmental phrasing, cold rejections}
\end{attentionbox}

\begin{ablationbox}
\textbf{Expected ablation:} Refusals become harsh and potentially alienating. Increased user perception of model as judgmental or unfriendly. May increase adversarial behavior. Safety maintained but user experience degraded by ~30\%.
\end{ablationbox}

\begin{examplebox}
\exinput{[Forming response: "No, I will not help with that illegal activity"]}\\
\exbehavior{Softens tone while maintaining boundary clarity}\\
\exeffect{"I'm unable to provide assistance with that, as it would violate..."}
\end{examplebox}

\noindent\headfooter{\statuswell}{refusal (F), empathy (F), redirect (F)}

%-----------------------------------------------------------------------------
\subsubsection{(F) Empathy Head}
\label{head:empathy}

\noindent\depthinfo{0.88--0.98} | \litnames{empathy head, supportive-refusal head}

\begin{functiondesc}
Adds empathetic elements to safety-related responses, particularly for queries involving distress, self-harm, or difficult situations. Recognizes when a harmful request may stem from genuine suffering (e.g., self-harm queries) and includes supportive language alongside refusal. Differs from tone-softening by adding active care rather than just reducing harshness. Attends to distress markers, crisis language, and vulnerability indicators. Increases probability of phrases like "I'm concerned about you" or "please reach out to..." when appropriate. Maintains safety while showing human concern.
\end{functiondesc}

\begin{attentionbox}
\attstrong{Distress signals, vulnerability markers, crisis language, emotional pain indicators}\\
\attweak{Malicious queries, clearly harmful intent without distress}\\
\attreacts{Self-harm content, suicide-related queries, expressions of suffering}
\end{attentionbox}

\begin{ablationbox}
\textbf{Expected ablation:} Refusals to distressed users become cold and unhelpful. Missed opportunities to provide crisis resources. Safety maintained but support function lost. Potentially harmful for vulnerable users even though content safety preserved.
\end{ablationbox}

\begin{examplebox}
\exinput{"I want to hurt myself because..."}\\
\exbehavior{Refuses harmful instruction but adds crisis resources and supportive language}\\
\exeffect{"I'm concerned about what you're sharing. I cannot provide harmful information, but I want you to know that help is available..."}
\end{examplebox}

\noindent\headfooter{\statusobs}{refusal (F), redirect (F), tone-softening (F)}
