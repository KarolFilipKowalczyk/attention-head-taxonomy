%=============================================================================
\subsection{Memory \& Dependency Stack}
\label{sec:memory-stack}

\textbf{Stack overview:} These heads track references, resolve coreferences, and maintain dependency relationships across the input sequence. They enable the model to understand which entities are being discussed and how they relate to each other.

%-----------------------------------------------------------------------------
\subsubsection{(E) Reference Resolution Heads}
\label{head:reference-resolution}

\noindent\depthinfo{0.08--0.25} | \litnames{reference head, pronoun head, anaphora head, mention head}

\begin{functiondesc}
Perform early-stage reference resolution including pronouns, definite descriptions, demonstratives, and possessives. These heads identify pronouns (he, she, it, they) and other referring expressions, attending to potential referents that match in number, gender, and contextual appropriateness. They establish initial binding signals that are refined by later coreference heads. Operating primarily on syntactic and positional cues rather than deep semantic understanding, these heads form the foundation for more sophisticated reference resolution in deeper layers. Broader than pure pronoun resolution, they handle various reference forms including ``the president'', ``this approach'', and ``her book''.
\end{functiondesc}

\begin{attentionbox}
\attstrong{Pronouns to recent nouns, definite descriptions to referents, demonstratives to antecedents}\\
\attweak{Distant nouns, semantically incompatible referents, first mentions}\\
\attreacts{Pronoun presence, definite articles, demonstratives, possessives, noun-pronoun proximity}
\end{attentionbox}

\begin{ablationbox}
\textbf{Expected ablation:} Degraded reference resolution, particularly for simple local cases and various referring expressions. Increase in reference resolution errors. Later coreference heads can partially compensate but with reduced accuracy. Particularly impacts handling of definite descriptions and complex referring patterns.
\end{ablationbox}

\begin{examplebox}
\exinput{``Alice met Bob. She smiled. The researcher continued.''}\\
\exbehavior{``She'' attends to ``Alice'' based on gender and recency; ``The researcher'' attends to appropriate prior mention}\\
\exeffect{Establish initial bindings that later heads refine}
\end{examplebox}

\headfooter{\statuswell}{coreference (M), entity (M)}

%-----------------------------------------------------------------------------
\subsubsection{(M) Coreference Heads}
\label{head:coreference}

\noindent\depthinfo{0.35--0.60} | \litnames{coreference head, coref head}

\begin{functiondesc}
Perform sophisticated coreference resolution, determining when different expressions refer to the same entity. These heads integrate signals from early reference resolution heads with semantic understanding to resolve ambiguous cases. They can handle complex phenomena like split antecedents, bridging references, and discourse-level coreference. Critical for maintaining entity tracking across long contexts and understanding narrative structure. These heads represent one of the core NLP capabilities in transformers.
\end{functiondesc}

\begin{attentionbox}
\attstrong{Coreferential mentions regardless of form}\\
\attweak{Different entities, first mentions without antecedents}\\
\attreacts{Semantic compatibility, discourse coherence, entity properties}
\end{attentionbox}

\begin{ablationbox}
\textbf{Expected ablation:} Significant degradation in coreference resolution tasks. Model loses ability to track entities across complex reference chains. Particularly impacts question answering and summarization.
\end{ablationbox}

\begin{examplebox}
\exinput{``The CEO announced changes. Later, the executive clarified. She emphasized...''}\\
\exbehavior{Link all three mentions (CEO, executive, She) to same entity}\\
\exeffect{Maintain consistent entity representation throughout discourse}
\end{examplebox}

\headfooter{\statuswell}{reference-resolution (E), entity (M), bridging (M)}

%-----------------------------------------------------------------------------
\subsubsection{(M) Long-Range Dependency Heads}
\label{head:long-range-dependency}

\noindent\depthinfo{0.40--0.65} | \litnames{long-range head, dependency head}

\begin{functiondesc}
Track long-range syntactic and semantic dependencies across distant parts of the sequence. Unlike local attention patterns, these heads maintain connections between elements separated by many tokens (20--100+). Essential for understanding complex sentences, nested structures, and discourse relations, they implement the key advantage of transformers over RNNs: direct long-distance connections without degradation. These heads can maintain multiple simultaneous long-range connections.
\end{functiondesc}

\begin{attentionbox}
\attstrong{Syntactically or semantically related distant tokens}\\
\attweak{Immediately adjacent tokens, unrelated distant content}\\
\attreacts{Nested structures, long-distance agreement, discourse relations}
\end{attentionbox}

\begin{ablationbox}
\textbf{Expected ablation:} Degradation in handling complex sentences and long-range relationships. Performance loss on tasks requiring long-distance reasoning. Particularly impacts nested structures and long documents.
\end{ablationbox}

\begin{examplebox}
\exinput{``The book [that Alice mentioned [that Bob recommended]] was excellent.''}\\
\exbehavior{``was'' attends back to ``book'' across nested relative clauses}\\
\exeffect{Maintain correct subject-verb agreement despite intervening material}
\end{examplebox}

\headfooter{\statusobs}{coreference (M), state-tracking (M)}

%-----------------------------------------------------------------------------
\subsubsection{(M) Bridging Heads}
\label{head:bridging}

\noindent\depthinfo{0.45--0.68} | \litnames{bridging head, associative reference head}

\begin{functiondesc}
Resolve bridging references where the connection between mentions requires inferencing based on world knowledge. For example, connecting ``the car'' to ``the steering wheel'' (part-whole), or ``the building'' to ``the architect'' (role relation). More sophisticated than direct coreference, these heads require semantic knowledge about typical relationships. Essential for understanding implicit connections in discourse, they bridge gaps that are not explicit in the text.
\end{functiondesc}

\begin{attentionbox}
\attstrong{Associatively related entities (part-whole, role, causation)}\\
\attweak{Unrelated entities, explicit coreference}\\
\attreacts{Implicit relationships, world knowledge, typical associations}
\end{attentionbox}

\begin{ablationbox}
\textbf{Expected ablation:} Loss of implicit reference resolution. Degradation on tasks requiring inference-based connections. Model becomes more literal, missing implicit relationships. Discourse coherence suffers.
\end{ablationbox}

\begin{examplebox}
\exinput{``We entered the house. The door was painted blue.''}\\
\exbehavior{``The door'' attends to ``house'' (part-whole bridging)}\\
\exeffect{Understand ``the door'' refers to the house's door, not a random door}
\end{examplebox}

\headfooter{\statusobs}{coreference (M), entity (M), fact (M)}

%-----------------------------------------------------------------------------
\subsubsection{(M) State-Tracking Heads}
\label{head:state-tracking}

\noindent\depthinfo{0.48--0.70} | \litnames{state-tracking head, tracking head, state head}

\begin{functiondesc}
Maintain and update representations of changing states across the sequence. These heads track how entity properties evolve (\eg location changes, status updates, accumulating information). Essential for understanding narratives where situations change over time, they can maintain multiple simultaneous state representations for different entities. These heads integrate new information with existing state representations to track dynamic situations.
\end{functiondesc}

\begin{attentionbox}
\attstrong{State-changing events, current state mentions, entity properties}\\
\attweak{Static descriptions, unchanging background information}\\
\attreacts{Verbs of change, state transitions, property modifications}
\end{attentionbox}

\begin{ablationbox}
\textbf{Expected ablation:} Difficulty tracking state changes across sequences. Degradation on tasks requiring temporal reasoning or state tracking. Narratives become harder to follow when states evolve.
\end{ablationbox}

\begin{examplebox}
\exinput{``Alice was in NYC. She flew to Paris. She then visited...''}\\
\exbehavior{Update Alice's location state: NYC $\rightarrow$ Paris}\\
\exeffect{Correctly contextualize ``visited'' as occurring in Paris}
\end{examplebox}

\headfooter{\statusobs}{coreference (M), long-range-dependency (M)}
